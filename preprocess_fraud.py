# -*- coding: utf-8 -*-
"""
å¤„ç†æ¬ºè¯ˆå¯¹è¯æ•°æ®çš„è„šæœ¬
åˆ†åˆ«å¤„ç†è®­ç»ƒå’Œæµ‹è¯•æ–‡ä»¶
"""

import pandas as pd
import re
import json
import os
import sys
import numpy as np
from pathlib import Path
import random


def clean_dialogue_text(text):
    """
    æ¸…æ´—å¯¹è¯æ–‡æœ¬ï¼Œç§»é™¤è§’è‰²æ ‡è®°å’Œå¤šä½™æ ¼å¼
    """
    if not isinstance(text, str):
        return ""

    # ç§»é™¤"éŸ³é¢‘å†…å®¹ï¼š"å‰ç¼€
    if text.startswith("éŸ³é¢‘å†…å®¹ï¼š"):
        text = text[5:]

    # ç§»é™¤left:/right:è§’è‰²æ ‡è®°
    text = re.sub(r'(left:|right:)\s*', '', text)

    # ç§»é™¤å¤šä½™çš„æ˜Ÿå·ã€æ¢è¡Œå’Œç©ºç™½
    text = re.sub(r'\*+', '', text)
    text = re.sub(r'\n+', ' ', text)
    text = re.sub(r'\s+', ' ', text)

    # ç§»é™¤å¯¹è¯æ ‡è®°å’Œå¼•å·
    text = re.sub(r'ã€.*?ã€‘', '', text)
    text = text.replace('"', '').replace("'", "")

    return text.strip()


def process_csv_file(file_path, file_type="train"):
    """
    å¤„ç†å•ä¸ªCSVæ–‡ä»¶
    """
    print(f"\nğŸ“‹ å¤„ç†{file_type}æ–‡ä»¶: {file_path}")

    if not os.path.exists(file_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return None

    # è¯»å–CSVæ–‡ä»¶
    try:
        # å°è¯•ä¸åŒçš„ç¼–ç 
        encodings = ['utf-8', 'gbk', 'gb2312', 'latin1']
        df = None

        for encoding in encodings:
            try:
                df = pd.read_csv(file_path, encoding=encoding)
                print(f"âœ… ä½¿ç”¨ç¼–ç : {encoding}")
                break
            except UnicodeDecodeError:
                continue

        if df is None:
            print(f"âŒ æ— æ³•è¯»å–æ–‡ä»¶ {file_path}")
            return None
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥ - {e}")
        return None

    print(f"ğŸ“Š æ•°æ®å½¢çŠ¶: {df.shape}")
    print(f"ğŸ“ åˆ—å: {df.columns.tolist()}")

    # è‡ªåŠ¨æ£€æµ‹æ–‡æœ¬åˆ—å’Œæ ‡ç­¾åˆ—
    text_col = None
    label_col = None

    # æŸ¥æ‰¾æ–‡æœ¬åˆ—
    text_keywords = ['text', 'content', 'dialogue', 'å¯¹è¯', 'æ–‡æœ¬', 'å†…å®¹', 'specific_dialogue_content']
    for col in df.columns:
        col_lower = str(col).lower()
        for keyword in text_keywords:
            if keyword in col_lower:
                text_col = col
                print(f"âœ… æ‰¾åˆ°æ–‡æœ¬åˆ—: {text_col}")
                break
        if text_col:
            break

    if not text_col:
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨ç¬¬ä¸€åˆ—
        text_col = df.columns[0]
        print(f"âš ï¸  æœªæ‰¾åˆ°æ–‡æœ¬åˆ—ï¼Œä½¿ç”¨ç¬¬ä¸€åˆ—: {text_col}")

    # æŸ¥æ‰¾æ ‡ç­¾åˆ—
    label_keywords = ['label', 'fraud', 'è¯ˆéª—', 'æ¬ºè¯ˆ', 'is_fraud', 'is_fraudulent']
    for col in df.columns:
        col_lower = str(col).lower()
        for keyword in label_keywords:
            if keyword in col_lower:
                label_col = col
                print(f"âœ… æ‰¾åˆ°æ ‡ç­¾åˆ—: {label_col}")
                break
        if label_col:
            break

    if not label_col:
        print(f"âŒ æœªæ‰¾åˆ°æ ‡ç­¾åˆ—")
        return None

    # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
    print(f"\nğŸ“„ æ•°æ®é¢„è§ˆï¼ˆå‰3è¡Œï¼‰:")
    for i in range(min(3, len(df))):
        text_preview = str(df.iloc[i][text_col])
        if len(text_preview) > 50:
            text_preview = text_preview[:50] + "..."

        label_val = df.iloc[i][label_col]
        print(f"  è¡Œ {i}: æ–‡æœ¬={text_preview}, æ ‡ç­¾={label_val}")

    # æ¸…æ´—æ–‡æœ¬
    print("ğŸ§¹ æ¸…æ´—å¯¹è¯æ–‡æœ¬...")
    df['cleaned_text'] = df[text_col].apply(clean_dialogue_text)

    # è½¬æ¢æ ‡ç­¾
    print("ğŸ·ï¸  è½¬æ¢æ ‡ç­¾...")

    def convert_label(x):
        if pd.isna(x):
            return 1  # é»˜è®¤æ¬ºè¯ˆ
        x_str = str(x).upper().strip()
        if x_str in ['TRUE', 'T', '1', 'æ˜¯', 'YES', 'Y', 'æ¬ºè¯ˆ', 'FRAUD', 'å®¢æœè¯ˆéª—', 'é“¶è¡Œè¯ˆéª—']:
            return 1
        elif x_str in ['FALSE', 'F', '0', 'å¦', 'NO', 'N', 'æ­£å¸¸', 'NORMAL']:
            return 0
        else:
            # å°è¯•è½¬æ¢ä¸ºæ•°å­—
            try:
                val = float(x)
                return 1 if val > 0.5 else 0
            except:
                return 1  # é»˜è®¤æ¬ºè¯ˆ

    df['label'] = df[label_col].apply(convert_label)

    print(f"âœ… {file_type}æ•°æ®å¤„ç†å®Œæˆ: {len(df)} æ¡è®°å½•")
    print(f"   æ¬ºè¯ˆæ ·æœ¬: {sum(df['label'])} æ¡ ({sum(df['label']) / len(df) * 100:.1f}%)")
    print(f"   æ­£å¸¸æ ·æœ¬: {len(df) - sum(df['label'])} æ¡ ({(len(df) - sum(df['label'])) / len(df) * 100:.1f}%)")

    return df


def save_bert_format(data, filename, output_dir):
    """
    ä¿å­˜ä¸ºBERT-Attackæ ¼å¼
    """
    output_path = output_dir / filename
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write("text_a\tlabel\n")
        for _, row in data.iterrows():
            text = row['cleaned_text']
            label = row['label']
            if text and len(text.strip()) > 0:  # åªä¿å­˜éç©ºæ–‡æœ¬
                f.write(f"{text}\t{label}\n")

    return output_path


def main():
    """ä¸»å‡½æ•° - åˆ†åˆ«å¤„ç†è®­ç»ƒå’Œæµ‹è¯•æ–‡ä»¶"""
    print("=" * 60)
    print("ğŸ¯ æ¬ºè¯ˆå¯¹è¯æ•°æ®é¢„å¤„ç†ç³»ç»Ÿ ")
    print("(åˆ†åˆ«å¤„ç†è®­ç»ƒå’Œæµ‹è¯•æ–‡ä»¶)")
    print("=" * 60)

    print(f"å½“å‰ç›®å½•: {Path.cwd()}")
    print(f"Pythonç‰ˆæœ¬: {sys.version}")

    # ========== ç¡¬ç¼–ç æ–‡ä»¶è·¯å¾„ ==========
    TRAIN_FILE = "data/train_result.csv"  # è®­ç»ƒæ–‡ä»¶
    TEST_FILE = "data/test_result.csv"  # æµ‹è¯•æ–‡ä»¶

    # ========== åˆ›å»ºè¾“å‡ºç›®å½• ==========
    output_dir = Path("data/processed")
    output_dir.mkdir(parents=True, exist_ok=True)

    # ========== å¤„ç†è®­ç»ƒæ–‡ä»¶ ==========
    print(f"\n{'=' * 50}")
    print("å¤„ç†è®­ç»ƒæ–‡ä»¶")
    print(f"{'=' * 50}")

    if not os.path.exists(TRAIN_FILE):
        print(f"âŒ è®­ç»ƒæ–‡ä»¶ä¸å­˜åœ¨: {TRAIN_FILE}")
        print("è¯·å°† train_result.csv æ”¾åœ¨ data/ ç›®å½•ä¸‹")
        return

    train_df = process_csv_file(TRAIN_FILE, "è®­ç»ƒ")
    if train_df is None or len(train_df) == 0:
        print("âŒ è®­ç»ƒæ•°æ®å¤„ç†å¤±è´¥")
        return

    # ========== å¤„ç†æµ‹è¯•æ–‡ä»¶ ==========
    print(f"\n{'=' * 50}")
    print("å¤„ç†æµ‹è¯•æ–‡ä»¶")
    print(f"{'=' * 50}")

    if not os.path.exists(TEST_FILE):
        print(f"âŒ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {TEST_FILE}")
        print("è¯·å°† test_result.csv æ”¾åœ¨ data/ ç›®å½•ä¸‹")
        return

    test_df = process_csv_file(TEST_FILE, "æµ‹è¯•")
    if test_df is None or len(test_df) == 0:
        print("âŒ æµ‹è¯•æ•°æ®å¤„ç†å¤±è´¥")
        return

    # ========== ä¿å­˜æ–‡ä»¶ ==========
    print(f"\n{'=' * 50}")
    print("ä¿å­˜å¤„ç†åçš„æ–‡ä»¶")
    print(f"{'=' * 50}")

    # ä¿å­˜è®­ç»ƒé›†
    train_path = save_bert_format(train_df, "fraud_train.txt", output_dir)
    print(f"âœ… è®­ç»ƒé›†å·²ä¿å­˜: {train_path} ({len(train_df)} æ¡)")

    # ä¿å­˜æµ‹è¯•é›†
    test_path = save_bert_format(test_df, "fraud_test.txt", output_dir)
    print(f"âœ… æµ‹è¯•é›†å·²ä¿å­˜: {test_path} ({len(test_df)} æ¡)")

    # åˆ›å»ºå°æµ‹è¯•é›†ï¼ˆç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰
    test_small = test_df.head(min(100, len(test_df)))
    test_small_path = save_bert_format(test_small, "fraud_test_small.txt", output_dir)
    print(f"âœ… å°æµ‹è¯•é›†å·²ä¿å­˜: {test_small_path} ({len(test_small)} æ¡)")

    # åˆ›å»ºéªŒè¯é›†ï¼ˆä»è®­ç»ƒé›†ä¸­åˆ†å‰²ï¼‰
    print(f"\nğŸ“Š ä»è®­ç»ƒé›†ä¸­åˆ†å‰²éªŒè¯é›†...")
    from sklearn.model_selection import train_test_split

    # åˆ†å‰²è®­ç»ƒé›†ä¸ºè®­ç»ƒå’ŒéªŒè¯
    train_texts = train_df['cleaned_text'].tolist()
    train_labels = train_df['label'].tolist()

    train_texts_new, val_texts, train_labels_new, val_labels = train_test_split(
        train_texts, train_labels, test_size=0.2, random_state=42, stratify=train_labels
    )

    # åˆ›å»ºéªŒè¯é›†DataFrame
    val_df = pd.DataFrame({
        'cleaned_text': val_texts,
        'label': val_labels
    })

    val_path = save_bert_format(val_df, "fraud_val.txt", output_dir)
    print(f"âœ… éªŒè¯é›†å·²ä¿å­˜: {val_path} ({len(val_df)} æ¡)")

    # æ›´æ–°è®­ç»ƒé›†
    train_df_new = pd.DataFrame({
        'cleaned_text': train_texts_new,
        'label': train_labels_new
    })

    # è¦†ç›–åŸæ¥çš„è®­ç»ƒé›†
    train_path = save_bert_format(train_df_new, "fraud_train.txt", output_dir)
    print(f"âœ… æ›´æ–°åçš„è®­ç»ƒé›†å·²ä¿å­˜: {train_path} ({len(train_df_new)} æ¡)")

    # ========== æ•°æ®ç»Ÿè®¡ ==========
    print(f"\n{'=' * 50}")
    print("ğŸ“Š æœ€ç»ˆæ•°æ®ç»Ÿè®¡")
    print(f"{'=' * 50}")

    print(f"è®­ç»ƒé›†: {len(train_df_new)} æ¡")
    train_fraud = sum(train_df_new['label'])
    train_normal = len(train_df_new) - train_fraud
    print(f"  æ¬ºè¯ˆ: {train_fraud} æ¡ ({train_fraud / len(train_df_new) * 100:.1f}%)")
    print(f"  æ­£å¸¸: {train_normal} æ¡ ({train_normal / len(train_df_new) * 100:.1f}%)")

    print(f"\néªŒè¯é›†: {len(val_df)} æ¡")
    val_fraud = sum(val_df['label'])
    val_normal = len(val_df) - val_fraud
    print(f"  æ¬ºè¯ˆ: {val_fraud} æ¡ ({val_fraud / len(val_df) * 100:.1f}%)")
    print(f"  æ­£å¸¸: {val_normal} æ¡ ({val_normal / len(val_df) * 100:.1f}%)")

    print(f"\næµ‹è¯•é›†: {len(test_df)} æ¡")
    test_fraud = sum(test_df['label'])
    test_normal = len(test_df) - test_fraud
    print(f"  æ¬ºè¯ˆ: {test_fraud} æ¡ ({test_fraud / len(test_df) * 100:.1f}%)")
    print(f"  æ­£å¸¸: {test_normal} æ¡ ({test_normal / len(test_df) * 100:.1f}%)")

    print(f"\nå°æµ‹è¯•é›†: {len(test_small)} æ¡")
    small_fraud = sum(test_small['label'])
    small_normal = len(test_small) - small_fraud
    print(f"  æ¬ºè¯ˆ: {small_fraud} æ¡ ({small_fraud / len(test_small) * 100:.1f}%)")
    print(f"  æ­£å¸¸: {small_normal} æ¡ ({small_normal / len(test_small) * 100:.1f}%)")

    print("\n" + "=" * 60)
    print("ğŸ‰ æ•°æ®é¢„å¤„ç†å®Œæˆï¼")
    print("=" * 60)



if __name__ == "__main__":
    main()